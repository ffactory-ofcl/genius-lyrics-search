{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: swifter in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: joblib in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: click in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (5.9.6)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (2.1.4)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (2023.12.1)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (8.1.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0.1)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (23.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.8.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.17.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (3.0.9)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (3.0.39)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.1.6)\n",
      "Requirement already satisfied: stack-data in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.6.3)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.19.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (1.1.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.16.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.8.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (1.26.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3.post1)\n",
      "Requirement already satisfied: locket in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from partd>=1.2.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.4.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\paula\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk swifter swifter[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:59:58.618452Z",
     "start_time": "2024-01-07T09:59:58.607410Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import swifter\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:00.130448Z",
     "start_time": "2024-01-07T09:59:59.619116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "df = pd.read_csv('subset-song-lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:01.453221Z",
     "start_time": "2024-01-07T10:00:01.430381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of songs: 12295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>language_cld3</th>\n",
       "      <th>language_ft</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>4743</td>\n",
       "      <td>{}</td>\n",
       "      <td>Maybe cause I'm eatin\\nAnd these bastards fien...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   views  \\\n",
       "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1         Can I Live  rap      JAY-Z  1996  468624   \n",
       "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
       "3       Down and Out  rap    Cam'ron  2004  144404   \n",
       "4             Fly In  rap  Lil Wayne  2005   78271   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2                                            {}   \n",
       "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "4                                            {}   \n",
       "\n",
       "                                              lyrics  id language_cld3  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
       "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
       "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
       "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
       "\n",
       "  language_ft language  \n",
       "0          en       en  \n",
       "1          en       en  \n",
       "2          en       en  \n",
       "3          en       en  \n",
       "4          en       en  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"number of songs: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:04.750355Z",
     "start_time": "2024-01-07T10:00:04.744511Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\paula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\paula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:05.589844Z",
     "start_time": "2024-01-07T10:00:05.565727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12064, 12295)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df[df[\"language\"] == \"en\"]), len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:17:54.823173Z",
     "start_time": "2024-01-07T10:17:53.241227Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "# Create a copy of the dataframe\n",
    "df_proc = df.copy()\n",
    "\n",
    "# Select only english songs\n",
    "df_proc = df_proc[df_proc[\"language\"] == \"en\"]\n",
    "\n",
    "# Select columns we care about\n",
    "df_proc = df_proc[[\"title\", \"lyrics\", \"views\"]]\n",
    "\n",
    "# Convert to lowercase\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.lower()\n",
    "# Remove any non-alphanumeric / whitespace characters\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.replace(re.compile(r\"[^\\w\\s]\"), \"\", regex=True)\n",
    "# Remove newlines\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.replace(\"\\n\", \" \", regex=False)\n",
    "# Remove text between square brackets\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.replace(re.compile(r\"\\[.{0,100}\\]\"), \"\", regex=True)\n",
    "# Split text into words\n",
    "df_proc[\"tokens\"] = df_proc[\"lyrics\"].str.rsplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:47.261930Z",
     "start_time": "2024-01-07T10:00:11.500207Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937ede1a4eb44221a9697fe5ccc7da25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/12064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove stopwords and stem tokens\n",
    "def remove_stopwords_and_stem(tokens):\n",
    "    return \" \".join([ps.stem(token) for token in tokens if token not in stopwords_en])\n",
    "\n",
    "\n",
    "df_proc[\"text\"] = df_proc[\"tokens\"].swifter.apply(remove_stopwords_and_stem)\n",
    "df_proc.drop(columns=[\"tokens\", \"lyrics\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:51.886296Z",
     "start_time": "2024-01-07T10:00:51.862829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (Young Mula, baby!)\\nI say, he's so sweet, make her wanna lick\",\n",
       " 'intro lil wayn haha uhhuh homo young mula babi say he sweet make wanna lick wrapper remix babi vers ')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the original lyrics with the tokenized lyrics\n",
    "(df.iloc[5][\"lyrics\"][0:100], df_proc.iloc[5][\"text\"][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:56.242240Z",
     "start_time": "2024-01-07T10:00:56.201640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>173166</td>\n",
       "      <td>choru opera steve camron killa cam killa cam c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>468624</td>\n",
       "      <td>produc irv gotti intro yeah hah yeah rocafella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>4743</td>\n",
       "      <td>mayb caus im eatin bastard fiend grub carri pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>144404</td>\n",
       "      <td>produc kany west brian miller intro camron kan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>78271</td>\n",
       "      <td>intro ask young boy gon second time around gon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title   views  \\\n",
       "0          Killa Cam  173166   \n",
       "1         Can I Live  468624   \n",
       "2  Forgive Me Father    4743   \n",
       "3       Down and Out  144404   \n",
       "4             Fly In   78271   \n",
       "\n",
       "                                                text  \n",
       "0  choru opera steve camron killa cam killa cam c...  \n",
       "1  produc irv gotti intro yeah hah yeah rocafella...  \n",
       "2  mayb caus im eatin bastard fiend grub carri pu...  \n",
       "3  produc kany west brian miller intro camron kan...  \n",
       "4  intro ask young boy gon second time around gon...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:01:03.954364Z",
     "start_time": "2024-01-07T10:01:03.704188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>choru opera steve camron killa cam killa cam c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>produc irv gotti intro yeah hah yeah rocafella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>mayb caus im eatin bastard fiend grub carri pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>produc kany west brian miller intro camron kan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>intro ask young boy gon second time around gon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                               text\n",
       "0          Killa Cam  choru opera steve camron killa cam killa cam c...\n",
       "1         Can I Live  produc irv gotti intro yeah hah yeah rocafella...\n",
       "2  Forgive Me Father  mayb caus im eatin bastard fiend grub carri pu...\n",
       "3       Down and Out  produc kany west brian miller intro camron kan...\n",
       "4             Fly In  intro ask young boy gon second time around gon..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as a pickle file\n",
    "torch.save(df_proc[[\"title\", \"text\"]], 'subset-documents.pkl')\n",
    "\n",
    "# Test if the pickle file is saved correctly\n",
    "df_reloaded = torch.load('subset-documents.pkl')\n",
    "df_reloaded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:01:24.590311Z",
     "start_time": "2024-01-07T10:01:24.579912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to Select Verses\n",
    "def getFirstVerses(lyricsString, amount):\n",
    "    verseList = re.split('\\n', lyricsString)\n",
    "    FinalList = [i for i in verseList if (len(i) > 1 and i[0] != '[')]\n",
    "    return \" \".join(FinalList[:amount])\n",
    "\n",
    "\n",
    "def getFirstVersesOfChorus(lyricsString, amount):\n",
    "    List = re.split('\\n', lyricsString)\n",
    "    verseList = [i for i in List if len(i) > 1]\n",
    "    for i in range(len(verseList)):\n",
    "        if \"[Chorus\" in verseList[i] or \"[Hook\" in verseList[i]:\n",
    "            return \" \".join(verseList[i + 1:i + amount + 1])\n",
    "    return getFirstVerses(lyricsString, amount)\n",
    "\n",
    "\n",
    "def getRandomVerses(lyricsString, amount):\n",
    "    verseList = re.split('\\n', lyricsString)\n",
    "    FinalList = [i for i in verseList if (len(i) > 1 and i[0] != '[')]\n",
    "    rd = random.randint(0, len(FinalList) - amount)\n",
    "    return \" \".join(FinalList[rd:rd + amount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:02:13.193171Z",
     "start_time": "2024-01-07T10:02:13.185882Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to Degrade message\n",
    "\n",
    "#Function to create typo by neighbouring letter\n",
    "NeighbouringKeys = {\n",
    "    'q': \"qwas\",\n",
    "    'w': \"qwase\",\n",
    "    'e': \"wsedr\",\n",
    "    'r': \"edrft\",\n",
    "    't': \"rftgy\",\n",
    "    'y': \"tgyhu\",\n",
    "    'u': \"yhuji\",\n",
    "    'i': \"ujiko\",\n",
    "    'o': \"ikolp\",\n",
    "    'p': \"olp\",\n",
    "    'a': \"qwasz\",\n",
    "    's': \"wazsxed\",\n",
    "    'd': \"sxedcrf\",\n",
    "    'f': \"dcrfvtg\",\n",
    "    'g': \"fvtgbyh\",\n",
    "    'h': \"gbyhnuj\",\n",
    "    'j': \"hnujmik\",\n",
    "    'k': \"jmikol\",\n",
    "    'l': \"kolp\",\n",
    "    'z': \"azsx\",\n",
    "    'x': \"zsxdc\",\n",
    "    'c': \"xdcfv\",\n",
    "    'v': \"cfvgb\",\n",
    "    'b': \"vgbhn\",\n",
    "    'n': \"bhnjm\",\n",
    "    'm': \"njmk\"\n",
    "}\n",
    "\n",
    "englishLetters = NeighbouringKeys.keys()\n",
    "\n",
    "\n",
    "def typos(text, prob=0.01):\n",
    "    resultingText = \"\"\n",
    "\n",
    "    for letter in text:\n",
    "        if not letter in englishLetters:\n",
    "            newLetter = letter\n",
    "        else:\n",
    "            if random.random() < prob:\n",
    "                newLetter = random.choice(NeighbouringKeys[letter])\n",
    "            else:\n",
    "                newLetter = letter\n",
    "        resultingText += newLetter\n",
    "\n",
    "    return resultingText\n",
    "\n",
    "\n",
    "#Function to (maybe) invert 2 adjacent letters (do force=True to force it to happen)\n",
    "def invertAdjacentLetters(text, force=False):\n",
    "    rd = random.randint(0, len(text) - 2)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters and text[rd + 1] in englishLetters:\n",
    "            return text[:rd] + text[rd + 1] + text[rd] + text[rd + 2:]\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        while not (text[rd] in englishLetters and text[rd + 1] in englishLetters):\n",
    "            rd = random.randint(0, len(text) - 2)\n",
    "        return text[:rd] + text[rd + 1] + text[rd] + text[rd + 2:]\n",
    "\n",
    "\n",
    "#Function to (maybe) remove a letter (do force=True to force it to happen)\n",
    "def removeLetter(text, force=False):\n",
    "    rd = random.randint(0, len(text) - 1)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters:\n",
    "            return text[:rd] + text[rd + 1:]\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        while not (text[rd] in englishLetters):\n",
    "            rd = random.randint(0, len(text) - 1)\n",
    "        return text[:rd] + text[rd + 1:]\n",
    "\n",
    "\n",
    "#Function to (maybe) double a letter (do force=True to force it to happen)\n",
    "def doubleLetter(text, force=False):\n",
    "    rd = random.randint(0, len(text) - 1)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters:\n",
    "            return text[:rd + 1] + text[rd] + text[rd + 1:]\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        while not (text[rd] in englishLetters):\n",
    "            rd = random.randint(0, len(text) - 1)\n",
    "        return text[:rd + 1] + text[rd] + text[rd + 1:]\n",
    "\n",
    "\n",
    "CommonMisspelling = {\"absence\": [\"absense\", \"absentse\", \"abcense\", \"absance\"], \"acceptable\": [\"acceptible\"], \"their\": [\"there\", \"they're\"],\n",
    "                     \"there\": [\"their\", \"they're\"], \"they're\": [\"their\", \"there\"], \"your\": [\"you're\"], \"you're\": [\"your\"]}\n",
    "\n",
    "# Add a common misspelling\n",
    "def addCommonMisspell(text):\n",
    "    for word in CommonMisspelling.keys():\n",
    "        if word in text:\n",
    "            return text.replace(word, random.choice(CommonMisspelling[word]))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:28:55.358663Z",
     "start_time": "2024-01-07T10:28:55.337489Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_qrels(df, n):\n",
    "    # Select only english songs\n",
    "    df = df[df[\"language\"] == \"en\"]\n",
    "    # Select columns we care about\n",
    "    df = df[[\"title\",\"lyrics\",\"views\"]]\n",
    "    # Add 'weight' column\n",
    "    max_views = max(df[\"views\"])\n",
    "    df[\"weight\"] = (df[\"views\"] / max_views) ** 0.5 * 0.5 + 0.1\n",
    "\n",
    "    df_sampled = df.sample(n // 2, weights='weight')\n",
    "    \n",
    "    def generate_positive_qrel(document):\n",
    "        text = document['lyrics']\n",
    "        rd = random.random()\n",
    "        if rd < 0.6:\n",
    "            query = getFirstVersesOfChorus(text, random.randint(1, 2))\n",
    "        elif rd < 0.9:\n",
    "            query = getFirstVerses(text, random.randint(1, 2))\n",
    "        else:\n",
    "            query = getRandomVerses(text, random.randint(1, 2))\n",
    "        \n",
    "        if random.randint(0, 3) == 0:\n",
    "            query = addCommonMisspell(query)\n",
    "        query = typos(query)\n",
    "        \n",
    "        for j in range(len(query)):\n",
    "            rand = random.randint(0, 50)\n",
    "            if rand == 0:\n",
    "                query = invertAdjacentLetters(query)\n",
    "            elif rand == 1:\n",
    "                query = removeLetter(query)\n",
    "            if rand == 2:\n",
    "                query = doubleLetter(query)\n",
    "        \n",
    "        doc_id = document.name\n",
    "        return pd.Series([query, doc_id, 1], index=['text', 'doc_id', 'relevance'])\n",
    "\n",
    "    def generate_negative_qrel(positive_qrel):\n",
    "        negative_doc_id = positive_qrel['doc_id']\n",
    "        while negative_doc_id == positive_qrel['doc_id']:\n",
    "            negative_doc_id = df.iloc[random.randint(0, len(df) - 1)].name\n",
    "    \n",
    "        return pd.Series([positive_qrel['text'], negative_doc_id, 0])\n",
    "\n",
    "    positive_qrels = df_sampled.apply(generate_positive_qrel, axis=1, result_type='expand')\n",
    "    negative_qrels = positive_qrels.apply(generate_negative_qrel, axis=1, result_type='broadcast')\n",
    "    \n",
    "    return pd.concat([positive_qrels, negative_qrels]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:28:57.706140Z",
     "start_time": "2024-01-07T10:28:57.324998Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save qrels as pickle file\n",
    "qrels = generate_qrels(df, 10000)\n",
    "torch.save(qrels, 'subset-qrels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smoke and maintain, and maitian And maintain, ...</td>\n",
       "      <td>9861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm single again, back on the prowwl I thought...</td>\n",
       "      <td>2699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Freeze! Motheerfuckker, I'm ill, fuck a fuckki...</td>\n",
       "      <td>4387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I know you like my style</td>\n",
       "      <td>6665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hey, I'm looking for (Good love, yeah)</td>\n",
       "      <td>537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>One-one-one-one, mic check one Galloin t a hoo...</td>\n",
       "      <td>3095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>So.. what is all this talk aobut the 'mrk of t...</td>\n",
       "      <td>10626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Y'all cain't stop it Y'all acin't stop, gangst...</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>I know I disppeared Anr poppd up inn Pérès maa...</td>\n",
       "      <td>9883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Shit's all good</td>\n",
       "      <td>8294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text doc_id relevance\n",
       "0     Smoke and maintain, and maitian And maintain, ...   9861         1\n",
       "1     I'm single again, back on the prowwl I thought...   2699         1\n",
       "2     Freeze! Motheerfuckker, I'm ill, fuck a fuckki...   4387         1\n",
       "3                              I know you like my style   6665         1\n",
       "4                Hey, I'm looking for (Good love, yeah)    537         1\n",
       "...                                                 ...    ...       ...\n",
       "9995  One-one-one-one, mic check one Galloin t a hoo...   3095         0\n",
       "9996  So.. what is all this talk aobut the 'mrk of t...  10626         0\n",
       "9997  Y'all cain't stop it Y'all acin't stop, gangst...     91         0\n",
       "9998  I know I disppeared Anr poppd up inn Pérès maa...   9883         0\n",
       "9999                                    Shit's all good   8294         0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "In order to be able to work on the data easier, we are going to make a string made out of our tokens, to then do the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:05:11.907348Z",
     "start_time": "2024-01-07T10:05:10.167435Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_proc['text'])\n",
    "\n",
    "feature = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:05:12.868856Z",
     "start_time": "2024-01-07T10:05:12.809721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Word    TF-IDF\n",
      "11036    cam  0.802686\n",
      "35284  killa  0.585084\n",
      "58006   sing  0.042337\n",
      "13452   clap  0.041190\n",
      "67073    uhh  0.018195\n",
      "...      ...       ...\n",
      "24439   fong  0.000000\n",
      "24440   foni  0.000000\n",
      "24441  fonic  0.000000\n",
      "24442   fonk  0.000000\n",
      "73198    𝑤𝑎𝑠  0.000000\n",
      "\n",
      "[73199 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "doc_vector = tfidf_matrix[0].toarray()\n",
    "#df with words and their tf-idf values\n",
    "df_tfidf = pd.DataFrame(list(zip(feature, doc_vector.flatten())), columns=['Word', 'TF-IDF'])\n",
    "\n",
    "df_tfidf = df_tfidf.sort_values(by='TF-IDF', ascending=False)\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'views', 'text', 'doc_vectors'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(df_proc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tokenized lyrics as a list of lists\n",
    "corpus = df_proc['text'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(tokens, model, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            n_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[token])\n",
    "    if n_words > 0:\n",
    "        feature_vector = np.divide(feature_vector, n_words)\n",
    "    return feature_vector\n",
    "\n",
    "df_proc['doc_vectors'] = [average_word_vectors(tokens, w2v_model, 100) for tokens in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     title                                               text\n",
      "12055    Do Ya Thing Remix  intro remix remix remix dipset killa cam duked...\n",
      "12067        Halftime Show  intro killa dipset check stat man seventyeight...\n",
      "6721              Me Killa  domm doom doom doom doom krazi killa bone kill...\n",
      "10098  Killa Cal Lifestyle  intro doc doom uh black knight nigga killa cal...\n",
      "6704                   BNK  hook whisper killa killa killa killa killa kil...\n",
      "10364       Juggalo Anthem  intro violent j killa kick anthem like juggalo...\n",
      "12059   Killa Season Intro  intro dukedagod get killa season let start shi...\n",
      "9296              D.P.G./K  intro bg knocc haha yeah orgin babi gangsta mo...\n",
      "4529      Still the Reason  vers 1 camron unh yo ten bird ill serv em brok...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#find similar songs to the first one.\n",
    "similarity_matrix = cosine_similarity(df_proc['doc_vectors'].tolist(), [df_proc['doc_vectors'].iloc[0]])\n",
    "similar_songs_indices = np.argsort(similarity_matrix[:, 0])[::-1]\n",
    "\n",
    "top_similar_songs = df_proc.iloc[similar_songs_indices[1:10]][['title', 'text']]\n",
    "print(top_similar_songs)\n",
    "#i am just trying things out rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(corpus,window_size,vocab_size,word_to_index,length_of_corpus,sample=None):\n",
    "\n",
    "    training_data =  []\n",
    "    training_sample_words =  []\n",
    "    for i,word in enumerate(corpus):\n",
    "\n",
    "        index_target_word = i\n",
    "        target_word = word\n",
    "        context_words = []\n",
    "\n",
    "        #when target word is the first word\n",
    "        if i == 0:  \n",
    "\n",
    "            # trgt_word_index:(0), ctxt_word_index:(1,2)\n",
    "            context_words = [corpus[x] for x in range(i + 1 , window_size + 1)] \n",
    "\n",
    "\n",
    "        #when target word is the last word\n",
    "        elif i == len(corpus)-1:\n",
    "\n",
    "            # trgt_word_index:(9), ctxt_word_index:(8,7), length_of_corpus = 10\n",
    "            context_words = [corpus[x] for x in range(length_of_corpus - 2 ,length_of_corpus -2 - window_size  , -1 )]\n",
    "\n",
    "        #When target word is the middle word\n",
    "        else:\n",
    "\n",
    "            #Before the middle target word\n",
    "            before_target_word_index = index_target_word - 1\n",
    "            for x in range(before_target_word_index, before_target_word_index - window_size , -1):\n",
    "                if x >=0:\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "            #After the middle target word\n",
    "            after_target_word_index = index_target_word + 1\n",
    "            for x in range(after_target_word_index, after_target_word_index + window_size):\n",
    "                if x < len(corpus):\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "\n",
    "        trgt_word_vector,ctxt_word_vector = get_one_hot_vectors(target_word,context_words,vocab_size,word_to_index)\n",
    "        training_data.append([trgt_word_vector,ctxt_word_vector])   \n",
    "        \n",
    "        if sample is not None:\n",
    "            training_sample_words.append([target_word,context_words])   \n",
    "        \n",
    "    return training_data,training_sample_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i am trying to adapt this code: https://github.com/rahul1728jha/Word2Vec_Implementation/blob/master/Word_2_Vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define other parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Set your desired window size\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43myour_vocabulary\u001b[49m)  \u001b[38;5;66;03m# Replace your_vocabulary with your actual vocabulary\u001b[39;00m\n\u001b[0;32m      4\u001b[0m word_to_index \u001b[38;5;241m=\u001b[39m your_word_to_index_dict  \u001b[38;5;66;03m# Replace with your actual word_to_index dictionary\u001b[39;00m\n\u001b[0;32m      5\u001b[0m length_of_corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(corpus)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'your_vocabulary' is not defined"
     ]
    }
   ],
   "source": [
    "# Define other parameters\n",
    "window_size = 5  # Set your desired window size\n",
    "vocab_size = len(your_vocabulary)  # Replace your_vocabulary with your actual vocabulary\n",
    "word_to_index = your_word_to_index_dict  # Replace with your actual word_to_index dictionary\n",
    "length_of_corpus = len(corpus)\n",
    "\n",
    "# Call the function to generate training data\n",
    "training_data, training_sample_words = generate_word_similarity_training_data(corpus, window_size, vocab_size, word_to_index, length_of_corpus, sample=None)\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=your_training_data, vector_size=your_vector_size, window=your_window_size, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_word(word1, word2, model):\n",
    "    vector1 = model.wv[word1]\n",
    "    vector2 = model.wv[word2]\n",
    "    similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = cosine_similarity_word('word1', 'word2', word2vec_model)\n",
    "print(f\"Similarity between 'word1' and 'word2': {similarity_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
