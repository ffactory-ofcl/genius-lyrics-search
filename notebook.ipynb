{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Collecting swifter\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
      "Requirement already satisfied: click in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: joblib in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (2.1.4)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (5.9.6)\n",
      "Collecting dask[dataframe]>=2.10.0\n",
      "  Downloading dask-2023.12.1-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (8.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.8.0)\n",
      "Collecting partd>=1.2.0\n",
      "  Downloading partd-1.4.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (23.2)\n",
      "Collecting cloudpickle>=1.5.0\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0.1)\n",
      "Collecting toolz>=0.10.0\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2023.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.17.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (4.0.9)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.13.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (3.0.9)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (1.1.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.1.6)\n",
      "Requirement already satisfied: stack-data in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.16.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (3.0.39)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.8.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.0.1)\n",
      "Building wheels for collected packages: swifter\n",
      "  Building wheel for swifter (setup.py): started\n",
      "  Building wheel for swifter (setup.py): finished with status 'done'\n",
      "  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16513 sha256=201c9933a2e9b6b98fb446761713acc7cc463baa4056b8ab4940750469b5acb8\n",
      "  Stored in directory: c:\\users\\paula\\appdata\\local\\pip\\cache\\wheels\\7b\\4a\\7e\\bcc48cf10e10fcf5b4dae464a66b523756db6b950e02129680\n",
      "Successfully built swifter\n",
      "Installing collected packages: toolz, locket, partd, cloudpickle, dask, swifter\n",
      "Successfully installed cloudpickle-3.0.0 dask-2023.12.1 locket-1.0.0 partd-1.4.1 swifter-1.4.0 toolz-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\paula\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk swifter swifter[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:59:58.618452Z",
     "start_time": "2024-01-07T09:59:58.607410Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import swifter\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:00.130448Z",
     "start_time": "2024-01-07T09:59:59.619116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "df = pd.read_csv('subset-song-lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:01.453221Z",
     "start_time": "2024-01-07T10:00:01.430381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of songs: 12295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>language_cld3</th>\n",
       "      <th>language_ft</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>4743</td>\n",
       "      <td>{}</td>\n",
       "      <td>Maybe cause I'm eatin\\nAnd these bastards fien...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   views  \\\n",
       "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1         Can I Live  rap      JAY-Z  1996  468624   \n",
       "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
       "3       Down and Out  rap    Cam'ron  2004  144404   \n",
       "4             Fly In  rap  Lil Wayne  2005   78271   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2                                            {}   \n",
       "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "4                                            {}   \n",
       "\n",
       "                                              lyrics  id language_cld3  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
       "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
       "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
       "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
       "\n",
       "  language_ft language  \n",
       "0          en       en  \n",
       "1          en       en  \n",
       "2          en       en  \n",
       "3          en       en  \n",
       "4          en       en  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"number of songs: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:04.750355Z",
     "start_time": "2024-01-07T10:00:04.744511Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ffactory/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ffactory/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:05.589844Z",
     "start_time": "2024-01-07T10:00:05.565727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12064, 12295)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df[df[\"language\"] == \"en\"]), len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:17:54.823173Z",
     "start_time": "2024-01-07T10:17:53.241227Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "# Create a copy of the dataframe\n",
    "df_proc = df.copy()\n",
    "\n",
    "# Select only english songs\n",
    "df_proc = df_proc[df_proc[\"language\"] == \"en\"]\n",
    "\n",
    "# Select columns we care about\n",
    "df_proc = df_proc[[\"title\", \"lyrics\", \"views\"]]\n",
    "\n",
    "# Convert to lowercase\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.lower()\n",
    "# Remove any non-alphanumeric / whitespace characters\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.replace(re.compile(r\"[^\\w\\s]\"), \"\", regex=True)\n",
    "# Remove newlines\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.replace(\"\\n\", \" \", regex=False)\n",
    "# Remove text between square brackets\n",
    "df_proc[\"lyrics\"] = df_proc[\"lyrics\"].str.replace(re.compile(r\"\\[.{0,100}\\]\"), \"\", regex=True)\n",
    "# Split text into words\n",
    "df_proc[\"tokens\"] = df_proc[\"lyrics\"].str.rsplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:47.261930Z",
     "start_time": "2024-01-07T10:00:11.500207Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810b32d7f5944c7bcb464d2b6805c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/12064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove stopwords and stem tokens\n",
    "def remove_stopwords_and_stem(tokens):\n",
    "    return \" \".join([ps.stem(token) for token in tokens if token not in stopwords_en])\n",
    "\n",
    "\n",
    "df_proc[\"text\"] = df_proc[\"tokens\"].swifter.apply(remove_stopwords_and_stem)\n",
    "df_proc.drop(columns=[\"tokens\", \"lyrics\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:51.886296Z",
     "start_time": "2024-01-07T10:00:51.862829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (Young Mula, baby!)\\nI say, he's so sweet, make her wanna lick\",\n",
       " 'intro lil wayn haha uhhuh homo young mula babi say he sweet make wanna lick wrapper remix babi vers ')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the original lyrics with the tokenized lyrics\n",
    "(df.iloc[5][\"lyrics\"][0:100], df_proc.iloc[5][\"text\"][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:00:56.242240Z",
     "start_time": "2024-01-07T10:00:56.201640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>173166</td>\n",
       "      <td>choru opera steve camron killa cam killa cam c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>468624</td>\n",
       "      <td>produc irv gotti intro yeah hah yeah rocafella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>4743</td>\n",
       "      <td>mayb caus im eatin bastard fiend grub carri pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>144404</td>\n",
       "      <td>produc kany west brian miller intro camron kan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>78271</td>\n",
       "      <td>intro ask young boy gon second time around gon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title   views  \\\n",
       "0          Killa Cam  173166   \n",
       "1         Can I Live  468624   \n",
       "2  Forgive Me Father    4743   \n",
       "3       Down and Out  144404   \n",
       "4             Fly In   78271   \n",
       "\n",
       "                                                text  \n",
       "0  choru opera steve camron killa cam killa cam c...  \n",
       "1  produc irv gotti intro yeah hah yeah rocafella...  \n",
       "2  mayb caus im eatin bastard fiend grub carri pu...  \n",
       "3  produc kany west brian miller intro camron kan...  \n",
       "4  intro ask young boy gon second time around gon...  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:01:03.954364Z",
     "start_time": "2024-01-07T10:01:03.704188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>choru opera steve camron killa cam killa cam c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>produc irv gotti intro yeah hah yeah rocafella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>mayb caus im eatin bastard fiend grub carri pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>produc kany west brian miller intro camron kan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>intro ask young boy gon second time around gon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                               text\n",
       "0          Killa Cam  choru opera steve camron killa cam killa cam c...\n",
       "1         Can I Live  produc irv gotti intro yeah hah yeah rocafella...\n",
       "2  Forgive Me Father  mayb caus im eatin bastard fiend grub carri pu...\n",
       "3       Down and Out  produc kany west brian miller intro camron kan...\n",
       "4             Fly In  intro ask young boy gon second time around gon..."
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as a pickle file\n",
    "torch.save(df_proc[[\"title\", \"text\"]], 'subset-documents.pkl')\n",
    "\n",
    "# Test if the pickle file is saved correctly\n",
    "df_reloaded = torch.load('subset-documents.pkl')\n",
    "df_reloaded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:01:24.590311Z",
     "start_time": "2024-01-07T10:01:24.579912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to Select Verses\n",
    "def getFirstVerses(lyricsString, amount):\n",
    "    verseList = re.split('\\n', lyricsString)\n",
    "    FinalList = [i for i in verseList if (len(i) > 1 and i[0] != '[')]\n",
    "    return \" \".join(FinalList[:amount])\n",
    "\n",
    "\n",
    "def getFirstVersesOfChorus(lyricsString, amount):\n",
    "    List = re.split('\\n', lyricsString)\n",
    "    verseList = [i for i in List if len(i) > 1]\n",
    "    for i in range(len(verseList)):\n",
    "        if \"[Chorus\" in verseList[i] or \"[Hook\" in verseList[i]:\n",
    "            return \" \".join(verseList[i + 1:i + amount + 1])\n",
    "    return getFirstVerses(lyricsString, amount)\n",
    "\n",
    "\n",
    "def getRandomVerses(lyricsString, amount):\n",
    "    verseList = re.split('\\n', lyricsString)\n",
    "    FinalList = [i for i in verseList if (len(i) > 1 and i[0] != '[')]\n",
    "    rd = random.randint(0, len(FinalList) - amount)\n",
    "    return \" \".join(FinalList[rd:rd + amount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:02:13.193171Z",
     "start_time": "2024-01-07T10:02:13.185882Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to Degrade message\n",
    "\n",
    "#Function to create typo by neighbouring letter\n",
    "NeighbouringKeys = {\n",
    "    'q': \"qwas\",\n",
    "    'w': \"qwase\",\n",
    "    'e': \"wsedr\",\n",
    "    'r': \"edrft\",\n",
    "    't': \"rftgy\",\n",
    "    'y': \"tgyhu\",\n",
    "    'u': \"yhuji\",\n",
    "    'i': \"ujiko\",\n",
    "    'o': \"ikolp\",\n",
    "    'p': \"olp\",\n",
    "    'a': \"qwasz\",\n",
    "    's': \"wazsxed\",\n",
    "    'd': \"sxedcrf\",\n",
    "    'f': \"dcrfvtg\",\n",
    "    'g': \"fvtgbyh\",\n",
    "    'h': \"gbyhnuj\",\n",
    "    'j': \"hnujmik\",\n",
    "    'k': \"jmikol\",\n",
    "    'l': \"kolp\",\n",
    "    'z': \"azsx\",\n",
    "    'x': \"zsxdc\",\n",
    "    'c': \"xdcfv\",\n",
    "    'v': \"cfvgb\",\n",
    "    'b': \"vgbhn\",\n",
    "    'n': \"bhnjm\",\n",
    "    'm': \"njmk\"\n",
    "}\n",
    "\n",
    "englishLetters = NeighbouringKeys.keys()\n",
    "\n",
    "\n",
    "def typos(text, prob=0.01):\n",
    "    resultingText = \"\"\n",
    "\n",
    "    for letter in text:\n",
    "        if not letter in englishLetters:\n",
    "            newLetter = letter\n",
    "        else:\n",
    "            if random.random() < prob:\n",
    "                newLetter = random.choice(NeighbouringKeys[letter])\n",
    "            else:\n",
    "                newLetter = letter\n",
    "        resultingText += newLetter\n",
    "\n",
    "    return resultingText\n",
    "\n",
    "\n",
    "#Function to (maybe) invert 2 adjacent letters (do force=True to force it to happen)\n",
    "def invertAdjacentLetters(text, force=False):\n",
    "    rd = random.randint(0, len(text) - 2)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters and text[rd + 1] in englishLetters:\n",
    "            return text[:rd] + text[rd + 1] + text[rd] + text[rd + 2:]\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        while not (text[rd] in englishLetters and text[rd + 1] in englishLetters):\n",
    "            rd = random.randint(0, len(text) - 2)\n",
    "        return text[:rd] + text[rd + 1] + text[rd] + text[rd + 2:]\n",
    "\n",
    "\n",
    "#Function to (maybe) remove a letter (do force=True to force it to happen)\n",
    "def removeLetter(text, force=False):\n",
    "    rd = random.randint(0, len(text) - 1)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters:\n",
    "            return text[:rd] + text[rd + 1:]\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        while not (text[rd] in englishLetters):\n",
    "            rd = random.randint(0, len(text) - 1)\n",
    "        return text[:rd] + text[rd + 1:]\n",
    "\n",
    "\n",
    "#Function to (maybe) double a letter (do force=True to force it to happen)\n",
    "def doubleLetter(text, force=False):\n",
    "    rd = random.randint(0, len(text) - 1)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters:\n",
    "            return text[:rd + 1] + text[rd] + text[rd + 1:]\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        while not (text[rd] in englishLetters):\n",
    "            rd = random.randint(0, len(text) - 1)\n",
    "        return text[:rd + 1] + text[rd] + text[rd + 1:]\n",
    "\n",
    "\n",
    "CommonMisspelling = {\"absence\": [\"absense\", \"absentse\", \"abcense\", \"absance\"], \"acceptable\": [\"acceptible\"], \"their\": [\"there\", \"they're\"],\n",
    "                     \"there\": [\"their\", \"they're\"], \"they're\": [\"their\", \"there\"], \"your\": [\"you're\"], \"you're\": [\"your\"]}\n",
    "\n",
    "# Add a common misspelling\n",
    "def addCommonMisspell(text):\n",
    "    for word in CommonMisspelling.keys():\n",
    "        if word in text:\n",
    "            return text.replace(word, random.choice(CommonMisspelling[word]))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:28:55.358663Z",
     "start_time": "2024-01-07T10:28:55.337489Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_qrels(df, n):\n",
    "    # Select only english songs\n",
    "    df = df[df[\"language\"] == \"en\"]\n",
    "    # Select columns we care about\n",
    "    df = df[[\"title\",\"lyrics\",\"views\"]]\n",
    "    # Add 'weight' column\n",
    "    max_views = max(df[\"views\"])\n",
    "    df[\"weight\"] = (df[\"views\"] / max_views) ** 0.5 * 0.5 + 0.1\n",
    "\n",
    "    df_sampled = df.sample(n // 2, weights='weight')\n",
    "    \n",
    "    def generate_positive_qrel(document):\n",
    "        text = document['lyrics']\n",
    "        rd = random.random()\n",
    "        if rd < 0.6:\n",
    "            query = getFirstVersesOfChorus(text, random.randint(1, 2))\n",
    "        elif rd < 0.9:\n",
    "            query = getFirstVerses(text, random.randint(1, 2))\n",
    "        else:\n",
    "            query = getRandomVerses(text, random.randint(1, 2))\n",
    "        \n",
    "        if random.randint(0, 3) == 0:\n",
    "            query = addCommonMisspell(query)\n",
    "        query = typos(query)\n",
    "        \n",
    "        for j in range(len(query)):\n",
    "            rand = random.randint(0, 50)\n",
    "            if rand == 0:\n",
    "                query = invertAdjacentLetters(query)\n",
    "            elif rand == 1:\n",
    "                query = removeLetter(query)\n",
    "            if rand == 2:\n",
    "                query = doubleLetter(query)\n",
    "        \n",
    "        doc_id = document.name\n",
    "        return pd.Series([query, doc_id, 1], index=['text', 'doc_id', 'relevance'])\n",
    "\n",
    "    def generate_negative_qrel(positive_qrel):\n",
    "        negative_doc_id = positive_qrel['doc_id']\n",
    "        while negative_doc_id == positive_qrel['doc_id']:\n",
    "            negative_doc_id = df.iloc[random.randint(0, len(df) - 1)].name\n",
    "    \n",
    "        return pd.Series([positive_qrel['text'], negative_doc_id, 0])\n",
    "\n",
    "    positive_qrels = df_sampled.apply(generate_positive_qrel, axis=1, result_type='expand')\n",
    "    negative_qrels = positive_qrels.apply(generate_negative_qrel, axis=1, result_type='broadcast')\n",
    "    \n",
    "    return pd.concat([positive_qrels, negative_qrels]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:28:57.706140Z",
     "start_time": "2024-01-07T10:28:57.324998Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save qrels as pickle file\n",
    "qrels = generate_qrels(df, 10000)\n",
    "torch.save(qrels, 'subset-qrels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intro: Syn</td>\n",
       "      <td>7865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brand Nubian baby, heere to lip it again And y...</td>\n",
       "      <td>11134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From a nickel and dime ass nigga</td>\n",
       "      <td>8475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Verse 1 (Killa Tay) We pump lugs, and punk thu...</td>\n",
       "      <td>11702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I) Fuck with your osul likee ethher</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>All in together now (no, now, now) What are yo...</td>\n",
       "      <td>9078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Bling bling, every ttime I come around your ci...</td>\n",
       "      <td>1016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Ha Huh mann Im trippiin out right now</td>\n",
       "      <td>2695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>All the ganggstas they gon' ride to tis</td>\n",
       "      <td>1822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>I could tell you wanna grab the mic because yo...</td>\n",
       "      <td>10079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text doc_id relevance\n",
       "0                                            Intro: Syn   7865         1\n",
       "1     Brand Nubian baby, heere to lip it again And y...  11134         1\n",
       "2                      From a nickel and dime ass nigga   8475         1\n",
       "3     Verse 1 (Killa Tay) We pump lugs, and punk thu...  11702         1\n",
       "4                  (I) Fuck with your osul likee ethher    230         1\n",
       "...                                                 ...    ...       ...\n",
       "9995  All in together now (no, now, now) What are yo...   9078         0\n",
       "9996  Bling bling, every ttime I come around your ci...   1016         0\n",
       "9997              Ha Huh mann Im trippiin out right now   2695         0\n",
       "9998            All the ganggstas they gon' ride to tis   1822         0\n",
       "9999  I could tell you wanna grab the mic because yo...  10079         0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "In order to be able to work on the data easier, we are going to make a string made out of our tokens, to then do the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:05:11.907348Z",
     "start_time": "2024-01-07T10:05:10.167435Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m----> 2\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf_proc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m feature \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_proc['text'])\n",
    "\n",
    "feature = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:05:12.868856Z",
     "start_time": "2024-01-07T10:05:12.809721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Word    TF-IDF\n",
      "10769        cam  0.800548\n",
      "34638      killa  0.588214\n",
      "56995       sing  0.042899\n",
      "13152       clap  0.041008\n",
      "65962        uhh  0.018107\n",
      "...          ...       ...\n",
      "24039   foodmart  0.000000\n",
      "24040  foodstamp  0.000000\n",
      "24041      fooey  0.000000\n",
      "24042       foof  0.000000\n",
      "72003        𝑤𝑎𝑠  0.000000\n",
      "\n",
      "[72004 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "doc_vector = tfidf_matrix[0].toarray()\n",
    "#df with words and their tf-idf values\n",
    "df_tfidf = pd.DataFrame(list(zip(feature, doc_vector.flatten())), columns=['Word', 'TF-IDF'])\n",
    "\n",
    "df_tfidf = df_tfidf.sort_values(by='TF-IDF', ascending=False)\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
